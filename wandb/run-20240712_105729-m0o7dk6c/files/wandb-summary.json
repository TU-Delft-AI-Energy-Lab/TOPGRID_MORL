{"step_1/reward_0": 0.07043650793650794, "step_1/reward_1": 0.0, "step_1/reward_2": -1.0, "_timestamp": 1720774678.0422697, "_runtime": 28.27087163925171, "_step": 32, "losses_1/value_loss": 290934.625, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.004712462425231934, "losses_1/entropy": 3.969304084777832, "losses_1/old_approx_kl": -0.007374316453933716, "losses_1/approx_kl": 0.00025112926959991455, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": -1.9073486328125e-06, "global_step": 32, "_wandb": {"runtime": 27}}