{"step_1/reward_0": 2.0, "step_1/reward_1": 1253.1144067794085, "step_1/reward_2": -157.39999999999534, "_timestamp": 1720772910.8072596, "_runtime": 132.4280595779419, "_step": 128, "losses_1/value_loss": 59052.109375, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.008720855228602886, "losses_1/entropy": 3.969404697418213, "losses_1/old_approx_kl": 0.006320007145404816, "losses_1/approx_kl": 0.0002253800630569458, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.0002162456512451172, "global_step": 128, "_wandb": {"runtime": 131}}