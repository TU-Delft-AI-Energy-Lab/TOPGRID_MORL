{"charts_1/learning_rate": 0.0003, "losses_1/value_loss": 1801.6072998046875, "losses_1/policy_loss": -0.08313202112913132, "losses_1/entropy": 4.594954013824463, "losses_1/old_approx_kl": 0.04380760341882706, "losses_1/approx_kl": 0.005065727047622204, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.005305111408233643, "global_step": 5, "_timestamp": 1719829189.889756, "_runtime": 3.4217140674591064, "_step": 5, "charts_1/episode_reward_sum": 267.08479119236534, "charts_1/episode": 0, "charts_1/episode_reward_0": 0.19295634920634921, "charts_1/episode_reward_1": 229.09183484315872, "charts_1/episode_reward_2": 37.80000000000028, "_wandb": {"runtime": 3}}