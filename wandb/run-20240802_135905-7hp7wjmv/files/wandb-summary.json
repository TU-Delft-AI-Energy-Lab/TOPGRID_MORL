{"train/reward_ScaledLinesCapacity": 0.00042054319906896287, "train/reward_ScaledTopoDepth": -0.00037037037037037035, "train/reward_SubstationSwitching": -0.00819672131147541, "train/grid2opsteps": 1416, "_timestamp": 1722600292.9123042, "_runtime": 347.5310580730438, "_step": 990, "eval/reward_ScaledLinesCapacity": 0.16216049911548663, "eval/reward_ScaledTopoDepth": -0.09251322751322567, "eval/reward_SubstationSwitching": -0.6666666666666667, "eval/steps": 1066.0, "losses_1/value_loss": 0.057626109570264816, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.08227282017469406, "losses_1/entropy": 3.5256459712982178, "losses_1/old_approx_kl": -0.020142018795013428, "losses_1/approx_kl": 0.06109434366226196, "losses_1/clipfrac": 0.2375, "losses_1/explained_variance": -1.5734655857086182, "global_step": 960, "_wandb": {"runtime": 347}}