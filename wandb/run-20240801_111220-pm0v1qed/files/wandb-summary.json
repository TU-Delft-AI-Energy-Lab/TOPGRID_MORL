{"train/reward_ScaledLinesCapacity": 0.0003295267927261187, "train/reward_ScaledDistance": 0.00047619047619047624, "train/reward_TopoAction": 0.0, "train/grid2opsteps": 2, "_timestamp": 1722503599.3191211, "_runtime": 58.523017168045044, "_step": 108, "eval/reward_ScaledLinesCapacity": 0.2597228956658987, "eval/reward_ScaledDistance": 0.3156922398589088, "eval/reward_TopoAction": -0.16666666666666666, "eval/steps": 2016.0, "losses_1/value_loss": 13.099390029907227, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.08110330253839493, "losses_1/entropy": 3.8663063049316406, "losses_1/old_approx_kl": -0.10978690534830093, "losses_1/approx_kl": 0.025865772739052773, "losses_1/clipfrac": 0.1777777835726738, "losses_1/explained_variance": -11.016552925109863, "global_step": 108, "_wandb": {"runtime": 58}}