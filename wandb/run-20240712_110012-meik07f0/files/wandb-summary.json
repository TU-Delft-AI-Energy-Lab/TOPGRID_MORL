{"step_1/reward_0": 2.0, "step_1/reward_1": 1516.37697724998, "step_1/reward_2": -187.8999999999936, "_timestamp": 1720774892.919647, "_runtime": 80.89088106155396, "_step": 32, "losses_1/value_loss": 295716.84375, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.016863256692886353, "losses_1/entropy": 3.9682397842407227, "losses_1/old_approx_kl": -0.008727103471755981, "losses_1/approx_kl": 0.0004961788654327393, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.0014113187789916992, "global_step": 32, "_wandb": {"runtime": 28}}