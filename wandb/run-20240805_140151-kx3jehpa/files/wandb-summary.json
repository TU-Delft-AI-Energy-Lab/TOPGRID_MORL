{"train/reward_ScaledLinesCapacity": 0.9225651416214792, "train/reward_L2RPN": 16017.257881641388, "train/reward_ScaledTopoDepth": -0.5760000000000038, "train/grid2opsteps": 2016, "_timestamp": 1722859426.0767689, "_runtime": 114.80779385566711, "_step": 263, "eval/reward_ScaledLinesCapacity": 0.2088097374654705, "eval/reward_L2RPN": 3965.307587544123, "eval/reward_ScaledTopoDepth": -0.1441428571428581, "eval/steps": 1011.5, "losses_1/value_loss": 11673676.0, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": 0.0065449923276901245, "losses_1/entropy": 3.796858549118042, "losses_1/old_approx_kl": 0.026449978351593018, "losses_1/approx_kl": 0.0261310413479805, "losses_1/clipfrac": 0.175, "losses_1/explained_variance": 0.0011260509490966797, "global_step": 256, "_wandb": {"runtime": 114}}