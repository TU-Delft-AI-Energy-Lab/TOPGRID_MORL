{"train/reward_ScaledLinesCapacity": 0.00019812732356148894, "train/reward_ScaledTopoDepth": -0.00021164021164021162, "train/reward_SubstationSwitching": 0.0, "train/grid2opsteps": 217, "_timestamp": 1722600619.4700358, "_runtime": 215.70397090911865, "_step": 479, "eval/reward_ScaledLinesCapacity": 0.0026573492335100948, "eval/reward_ScaledTopoDepth": -2.6455026455026453e-05, "eval/reward_SubstationSwitching": -10.875, "eval/steps": 43.5, "losses_1/value_loss": 810389.3125, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.013492248952388763, "losses_1/entropy": 3.8188862800598145, "losses_1/old_approx_kl": -0.005068451166152954, "losses_1/approx_kl": 0.009310020133852959, "losses_1/clipfrac": 0.0375, "losses_1/explained_variance": 0.0012403130531311035, "global_step": 448, "_wandb": {"runtime": 216}}