{"losses_1/value_loss": 584837.3125, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.1421930491924286, "losses_1/entropy": 4.527020454406738, "losses_1/old_approx_kl": 0.15141187608242035, "losses_1/approx_kl": 0.07453887164592743, "losses_1/clipfrac": 0.9115961998701095, "losses_1/explained_variance": 0.00328671932220459, "global_step": 354, "_timestamp": 1719929871.2272468, "_runtime": 78.90606474876404, "_step": 199, "charts_1/episode_reward_sum": 902.4284673213963, "charts_1/episode": 99, "charts_1/episode_reward_0": 0.0, "charts_1/episode_reward_1": 777.1284673213959, "charts_1/episode_reward_2": 125.3000000000004, "_wandb": {"runtime": 78}}