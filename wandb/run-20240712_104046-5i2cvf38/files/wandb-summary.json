{"step_1/reward_0": 0.0, "step_1/reward_1": 0.5943631529808044, "step_1/reward_2": -0.1, "_timestamp": 1720773685.2177272, "_runtime": 38.99495315551758, "_step": 32, "losses_1/value_loss": 58423.80859375, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.009752565994858742, "losses_1/entropy": 3.969289541244507, "losses_1/old_approx_kl": 0.003133803606033325, "losses_1/approx_kl": 9.692460298538208e-05, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.0020424723625183105, "global_step": 32, "_wandb": {"runtime": 38}}