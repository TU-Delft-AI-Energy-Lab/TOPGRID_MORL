{"step_1/reward_0": 0.000496031746031746, "step_1/reward_1": 0.0, "step_1/reward_2": -1.0, "_timestamp": 1720773275.5554478, "_runtime": 26.434992790222168, "_step": 32, "losses_1/value_loss": 184952.890625, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.009203106164932251, "losses_1/entropy": 3.969435214996338, "losses_1/old_approx_kl": 0.01064184308052063, "losses_1/approx_kl": 0.00041525065898895264, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.0008592605590820312, "global_step": 32, "_wandb": {"runtime": 25}}