{"step_1/reward_0": 0.0, "step_1/reward_1": 0.4428860545158386, "step_1/reward_2": -0.1, "_timestamp": 1720773551.4628236, "_runtime": 27.548154592514038, "_step": 32, "losses_1/value_loss": 120738.4921875, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.016072183847427368, "losses_1/entropy": 3.969200849533081, "losses_1/old_approx_kl": 0.0023193061351776123, "losses_1/approx_kl": 0.00017346441745758057, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.0004868507385253906, "global_step": 32, "_wandb": {"runtime": 26}}