{"train/reward_ScaledLinesCapacity": 0.0, "train/reward_ScaledTopoDepth": 0.0, "train/reward_SubstationSwitching": 0.0, "train/grid2opsteps": 125, "_timestamp": 1722599806.9839003, "_runtime": 147.43827939033508, "_step": 387, "eval/reward_ScaledLinesCapacity": 0.9134955345931126, "eval/reward_ScaledTopoDepth": -0.31999999999999557, "eval/reward_SubstationSwitching": -1.0, "eval/steps": 2016.0, "losses_1/value_loss": 0.1698642373085022, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.12516342103481293, "losses_1/entropy": 3.665546178817749, "losses_1/old_approx_kl": -0.05207648128271103, "losses_1/approx_kl": 0.06448294222354889, "losses_1/clipfrac": 0.259375, "losses_1/explained_variance": -4.250897407531738, "global_step": 384, "_wandb": {"runtime": 147}}