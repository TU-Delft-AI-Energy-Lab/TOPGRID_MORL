{"train/reward_ScaledLinesCapacity": 0.0002205654349098459, "train/reward_TopoDepth": -0.14285714285714285, "train/reward_MaxTopoDepth": -0.5238095238095238, "train/grid2opsteps": 88, "_timestamp": 1722584730.4868684, "_runtime": 235.77445340156555, "_step": 1024, "eval/reward_ScaledLinesCapacity": 8.255988708937873e-05, "eval/reward_TopoDepth": -0.07936507936507936, "eval/reward_MaxTopoDepth": -0.07936507936507936, "eval/steps": 2.0, "losses_1/value_loss": 12901.140625, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.0572710856795311, "losses_1/entropy": 3.4798743724823, "losses_1/old_approx_kl": 0.03051859885454178, "losses_1/approx_kl": 0.009850926697254181, "losses_1/clipfrac": 0.0875, "losses_1/explained_variance": 0.008017957210540771, "global_step": 1024, "_wandb": {"runtime": 235}}