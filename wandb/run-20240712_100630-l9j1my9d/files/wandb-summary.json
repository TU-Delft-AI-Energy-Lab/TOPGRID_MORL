{"step_1/reward_0": 0.001488095238095238, "step_1/reward_1": 0.0, "step_1/reward_2": -1.0, "_timestamp": 1720771700.9997542, "_runtime": 110.4674961566925, "_step": 74, "losses_1/value_loss": 208968.484375, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.027152739465236664, "losses_1/entropy": 3.9700427055358887, "losses_1/old_approx_kl": -0.009444311261177063, "losses_1/approx_kl": 0.0006225612014532089, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": -9.09566879272461e-05, "global_step": 64, "_wandb": {"runtime": 111}}