{"step_1/reward_0": 2.0, "step_1/reward_1": 1518.255196645856, "step_1/reward_2": -201.39999999999284, "_timestamp": 1720777116.6390662, "_runtime": 42.06739115715027, "_step": 32, "losses_1/value_loss": 293870.78125, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.0020549893379211426, "losses_1/entropy": 3.969341993331909, "losses_1/old_approx_kl": 0.01582157611846924, "losses_1/approx_kl": 0.0004266202449798584, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 2.467632293701172e-05, "global_step": 32, "_wandb": {"runtime": 41}}