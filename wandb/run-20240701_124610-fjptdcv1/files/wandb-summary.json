{"charts_1/learning_rate": 0.0003, "losses_1/value_loss": 1809.40771484375, "losses_1/policy_loss": -0.08433264493942261, "losses_1/entropy": 4.594943046569824, "losses_1/old_approx_kl": 0.02819366380572319, "losses_1/approx_kl": 0.004558885004371405, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": -0.00025081634521484375, "global_step": 5, "_timestamp": 1719830774.417374, "_runtime": 3.443950891494751, "_step": 5, "charts_1/episode_reward_sum": 267.3647911131385, "charts_1/episode": 0, "charts_1/episode_reward_0": 0.0, "charts_1/episode_reward_1": 229.5647911131382, "charts_1/episode_reward_2": 37.80000000000028, "_wandb": {"runtime": 3}}