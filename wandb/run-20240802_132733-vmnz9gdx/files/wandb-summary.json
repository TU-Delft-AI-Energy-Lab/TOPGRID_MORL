{"train/reward_ScaledLinesCapacity": 0.00013835664241854502, "train/reward_ScaledTopoDepth": -0.00010582010582010581, "train/reward_ScaledMaxTopoDepth": -0.0003968253968253968, "train/grid2opsteps": 85, "_timestamp": 1722598316.1908314, "_runtime": 262.9330635070801, "_step": 1024, "eval/reward_ScaledLinesCapacity": 0.0, "eval/reward_ScaledTopoDepth": 0.0, "eval/reward_ScaledMaxTopoDepth": 0.0, "eval/steps": 1.0, "losses_1/value_loss": 0.038256172090768814, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.11434543132781982, "losses_1/entropy": 3.3357677459716797, "losses_1/old_approx_kl": 0.038696758449077606, "losses_1/approx_kl": 0.07227231562137604, "losses_1/clipfrac": 0.209375, "losses_1/explained_variance": -1.425260066986084, "global_step": 1024, "_wandb": {"runtime": 262}}