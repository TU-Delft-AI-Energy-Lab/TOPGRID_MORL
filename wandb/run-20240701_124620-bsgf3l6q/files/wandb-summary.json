{"charts_1/learning_rate": 0.0003, "losses_1/value_loss": 3000.1767578125, "losses_1/policy_loss": -0.0827924981713295, "losses_1/entropy": 4.594997406005859, "losses_1/old_approx_kl": 0.010669231414794922, "losses_1/approx_kl": 0.005003154277801514, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": -0.007586956024169922, "global_step": 3, "_timestamp": 1719830785.8827114, "_runtime": 5.5616514682769775, "_step": 5, "charts_1/episode_reward_sum": 1636.0854849427892, "charts_1/episode": 0, "charts_1/episode_reward_0": 0.0, "charts_1/episode_reward_1": 1434.4854849427938, "charts_1/episode_reward_2": 201.5999999999953, "_wandb": {"runtime": 5}}