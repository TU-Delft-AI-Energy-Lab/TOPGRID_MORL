{"step_1/reward_0": 0.0, "step_1/reward_1": 332.0388294607401, "step_1/reward_2": -43.70000000000035, "_timestamp": 1720773730.5187154, "_runtime": 41.151957273483276, "_step": 32, "losses_1/value_loss": 65943.34375, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.02001781016588211, "losses_1/entropy": 3.969654083251953, "losses_1/old_approx_kl": -0.012334972620010376, "losses_1/approx_kl": 0.000579833984375, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.0014941096305847168, "global_step": 32, "_wandb": {"runtime": 39}}