{"train/reward_ScaledLinesCapacity": 0.0011812154613339248, "train/reward_TopoDepth": -1.5238095238095237, "train/reward_MaxTopoDepth": -1.9047619047619047, "train/grid2opsteps": 90, "_timestamp": 1722584891.1520035, "_runtime": 53.57386541366577, "_step": 116, "eval/reward_ScaledLinesCapacity": 0.1656475009895697, "eval/reward_TopoDepth": -193.82539682540568, "eval/reward_MaxTopoDepth": -193.84523809524694, "eval/steps": 1055.0, "losses_1/value_loss": 54715.83203125, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.12498842179775238, "losses_1/entropy": 3.9385628700256348, "losses_1/old_approx_kl": 0.021491773426532745, "losses_1/approx_kl": 0.06161326915025711, "losses_1/clipfrac": 0.353125, "losses_1/explained_variance": 0.004015624523162842, "global_step": 64, "_wandb": {"runtime": 54}}