{"train/reward_ScaledLinesCapacity": 0.07444270577338917, "train/reward_ScaledTopoDepth": -0.035396825396825475, "train/reward_SubstationSwitching": -0.058823529411764705, "train/grid2opsteps": 223, "_timestamp": 1722599623.0728843, "_runtime": 21.13113522529602, "_step": 68, "eval/reward_ScaledLinesCapacity": 0.15895883655972678, "eval/reward_ScaledTopoDepth": -0.102296296296299, "eval/reward_SubstationSwitching": -0.45, "eval/steps": 1010.5, "losses_1/value_loss": 2.5470025539398193, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.11031791567802429, "losses_1/entropy": 3.9273157119750977, "losses_1/old_approx_kl": 0.25679802894592285, "losses_1/approx_kl": 0.06608624756336212, "losses_1/clipfrac": 0.375, "losses_1/explained_variance": -15.124483108520508, "global_step": 64, "_wandb": {"runtime": 21}}