{"train/reward_ScaledLinesCapacity": 0.00042150442739950376, "train/reward_ScaledTopoDepth": -0.0006666666666666666, "train/reward_SubstationSwitching": 0.0, "train/grid2opsteps": 1185, "_timestamp": 1722846798.9102845, "_runtime": 110.58742141723633, "_step": 346, "eval/reward_ScaledLinesCapacity": 0.15946076875086787, "eval/reward_ScaledTopoDepth": -0.1921031746031704, "eval/reward_SubstationSwitching": -0.41666666666666663, "eval/steps": 1009.5, "losses_1/value_loss": 3.376040458679199, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.09159210324287415, "losses_1/entropy": 3.8281636238098145, "losses_1/old_approx_kl": 0.014534816145896912, "losses_1/approx_kl": 0.03170791268348694, "losses_1/clipfrac": 0.18125, "losses_1/explained_variance": -15.221778869628906, "global_step": 320, "_wandb": {"runtime": 110}}