{"train/reward_ScaledLinesCapacity": 0.0, "train/reward_ScaledTopoDepth": 0.0, "train/reward_SubstationSwitching": 0.0, "train/grid2opsteps": 3, "_timestamp": 1722675066.656169, "_runtime": 740.4295380115509, "_step": 867, "eval/reward_ScaledLinesCapacity": 0.4332584836145505, "eval/reward_ScaledTopoDepth": -0.16006613756613536, "eval/reward_SubstationSwitching": -3.0, "eval/steps": 1009.0, "losses_1/value_loss": 0.4069395065307617, "charts_1/learning_rate": 0.0005, "losses_1/policy_loss": -0.1000577062368393, "losses_1/entropy": 3.7365100383758545, "losses_1/old_approx_kl": 0.04119757562875748, "losses_1/approx_kl": 0.02185983397066593, "losses_1/clipfrac": 0.146875, "losses_1/explained_variance": -0.46894919872283936, "global_step": 832, "_wandb": {"runtime": 740}}