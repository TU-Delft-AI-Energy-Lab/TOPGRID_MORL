{"charts_1/learning_rate": 0.0003, "losses_1/value_loss": 137.33250427246094, "losses_1/policy_loss": -0.1001114472746849, "losses_1/entropy": 4.594940185546875, "losses_1/old_approx_kl": 0.021869340911507607, "losses_1/approx_kl": 0.008462329395115376, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.014369368553161621, "global_step": 3, "_timestamp": 1719830520.3783429, "_runtime": 1.368332862854004, "_step": 1, "charts_1/episode_reward_sum": 57.368729465537584, "charts_1/episode": 0, "charts_1/episode_reward_0": 0.04513888888888889, "charts_1/episode_reward_1": 49.32359057664871, "charts_1/episode_reward_2": 7.999999999999984, "_wandb": {"runtime": 1}}