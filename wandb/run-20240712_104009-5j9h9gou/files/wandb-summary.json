{"step_1/reward_0": 0.0, "step_1/reward_1": 0.2634279131889343, "step_1/reward_2": -0.1, "_timestamp": 1720773641.575091, "_runtime": 32.31980299949646, "_step": 32, "losses_1/value_loss": 162756.296875, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.015707850456237793, "losses_1/entropy": 3.9699156284332275, "losses_1/old_approx_kl": 0.0020370781421661377, "losses_1/approx_kl": 0.00020250678062438965, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.0010804533958435059, "global_step": 32, "_wandb": {"runtime": 31}}