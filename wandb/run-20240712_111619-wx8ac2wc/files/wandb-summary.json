{"step_1/reward_0": 0.0, "step_1/reward_1": 0.4310421347618103, "step_1/reward_2": -0.1, "_timestamp": 1720775796.9987428, "_runtime": 17.47943377494812, "_step": 32, "losses_1/value_loss": 99293.1953125, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.007375530898571014, "losses_1/entropy": 3.969843626022339, "losses_1/old_approx_kl": -0.008632928133010864, "losses_1/approx_kl": 0.00013919174671173096, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.001148819923400879, "global_step": 32, "_wandb": {"runtime": 16}}