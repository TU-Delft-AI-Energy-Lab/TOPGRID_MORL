{"step_1/reward_0": 0.0, "step_1/reward_1": 0.4167344570159912, "step_1/reward_2": -0.1, "_timestamp": 1720776606.1128058, "_runtime": 15.774333953857422, "_step": 32, "losses_1/value_loss": 138872.453125, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.015222571790218353, "losses_1/entropy": 3.9698519706726074, "losses_1/old_approx_kl": -0.004713863134384155, "losses_1/approx_kl": 0.0002903789281845093, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.0006658434867858887, "global_step": 32, "_wandb": {"runtime": 15}}