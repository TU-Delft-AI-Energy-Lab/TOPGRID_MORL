{"step_1/reward_0": 0.0, "step_1/reward_1": 0.4244958758354187, "step_1/reward_2": -0.1, "_timestamp": 1720777165.5562506, "_runtime": 30.20716953277588, "_step": 22, "losses_1/value_loss": 189886.890625, "charts_1/learning_rate": 0.0003, "losses_1/policy_loss": -0.040256403386592865, "losses_1/entropy": 3.970141887664795, "losses_1/old_approx_kl": 0.015909701585769653, "losses_1/approx_kl": 0.001121029257774353, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": 0.000491023063659668, "global_step": 16, "_wandb": {"runtime": 30}}