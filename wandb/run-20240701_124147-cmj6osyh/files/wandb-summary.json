{"charts_1/learning_rate": 0.0003, "losses_1/value_loss": 3492.0224609375, "losses_1/policy_loss": -0.09277601540088654, "losses_1/entropy": 4.59497594833374, "losses_1/old_approx_kl": 0.026371359825134277, "losses_1/approx_kl": 0.005818545818328857, "losses_1/clipfrac": 0.0, "losses_1/explained_variance": -0.004187822341918945, "global_step": 4, "_timestamp": 1719830512.2462294, "_runtime": 4.724962472915649, "_step": 5, "charts_1/episode_reward_sum": 330.16456242213224, "charts_1/episode": 0, "charts_1/episode_reward_0": 0.22123015873015872, "charts_1/episode_reward_1": 286.4433322634017, "charts_1/episode_reward_2": 43.50000000000036, "_wandb": {"runtime": 4}}